"""
Universal Binary Principle (UBP) Framework v3.1.1 - GLR Error Correction Module
Author: Euan Craig, New Zealand
Date: 18 August 2025

This module implements the comprehensive Golay-Leech-Resonance (GLR) error
correction framework with spatiotemporal coherence management, realm-specific
lattice structures, and advanced error correction algorithms.

It has been refactored from ubp_framework_v31.py to exist as a standalone,
dedicated error correction subsystem.
"""

import numpy as np
from typing import Dict, Any, List, Tuple, Optional, Union
from dataclasses import dataclass
import json
import time
import math

# Import configuration
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'config')) # Ensure ubp_config is found if needed for standalone
from ubp_config import get_config, RealmConfig

# Import Bitfield and OffBit from the bits module (dataclass)
from bits import Bitfield, OffBit 
# Import OffBitUtils from the renamed module
from offbit_utils import OffBitUtils

# Import HexDictionary
from hex_dictionary import HexDictionary


@dataclass
class GLRMetrics:
    """Comprehensive metrics for GLR error correction performance."""
    spatial_coherence: float
    temporal_coherence: float
    nrci_spatial: float
    nrci_temporal: float
    nrci_combined: float
    error_correction_rate: float
    lattice_efficiency: float
    resonance_stability: float
    correction_iterations: int
    convergence_time: float
    realm_synchronization: float = 0.0
    quantum_coherence: float = 0.0


@dataclass
class LatticeStructure:
    """Definition of a lattice structure for GLR error correction."""
    name: str
    coordination_number: int
    lattice_type: str
    symmetry_group: str
    basis_vectors: np.ndarray
    nearest_neighbors: List[Tuple[float, ...]]
    correction_weights: np.ndarray
    resonance_frequency: float
    crv_value: float = 0.0
    wavelength_nm: float = 0.0


@dataclass
class ErrorCorrectionResult:
    """Result of an error correction operation."""
    corrected_offbits: List[int]
    correction_applied: bool
    error_count: int
    correction_strength: float
    nrci_improvement: float
    execution_time: float
    method_used: str


class ComprehensiveErrorCorrectionFramework:
    """
    Enhanced GLR error correction framework implementing spatiotemporal
    coherence management with realm-specific lattice structures.
    
    This class provides the core error correction capabilities for the UBP
    framework, combining Golay[23,12] codes with Leech lattice projections
    and resonance-based temporal correction.
    
    Enhanced for v3.1 with better integration and performance.
    """
    
    def __init__(self, realm_name: str = "electromagnetic", 
                enable_error_correction: bool = True,
                hex_dictionary_instance: Optional[HexDictionary] = None):
        """
        Initialize the GLR framework for a specific computational realm.
        
        Args:
            realm_name: Name of the computational realm to configure for
            enable_error_correction: Whether to enable error correction (default: True)
            hex_dictionary_instance: Optional HexDictionary for data storage
        """
        self.config = get_config() # Get the global UBPConfig instance
        
        self.realm_name = realm_name
        self.enable_error_correction = enable_error_correction
        self.hex_dictionary = hex_dictionary_instance or HexDictionary()
        
        # Initialize lattice structures
        self.lattice_structures = self._initialize_lattice_structures()
        self.current_lattice = self.lattice_structures.get(realm_name, 
                                                        self.lattice_structures["electromagnetic"])
        
        # Error correction components
        self.correction_history = []
        self.temporal_buffer = [] 
        self.spatial_cache = {} 
        
        # GLR-specific parameters
        self.golay_generator_matrix = self._generate_golay_matrix()
        self.leech_lattice_basis = self._generate_leech_basis()
        self.resonance_frequencies = self._calculate_resonance_frequencies()
        
        # Performance metrics
        self.current_metrics = GLRMetrics(
            spatial_coherence=0.0,
            temporal_coherence=0.0,
            nrci_spatial=0.0,
            nrci_temporal=0.0,
            nrci_combined=0.0,
            error_correction_rate=0.0,
            lattice_efficiency=0.0,
            resonance_stability=0.0,
            correction_iterations=0,
            convergence_time=0.0
        )
        
        # Initialize metrics tracking
        self.metrics_history = []
        
        self.quantum_entanglement_matrix = np.eye(24)  # 24D Leech lattice dimension for conceptual link
        self.realm_coupling_coefficients = self._calculate_realm_coupling()
        self.adaptive_threshold = 0.95  # Adaptive error correction threshold (0.0 to 1.0)
        
        print(f"âœ… GLR Error Correction Framework v3.1 Initialized")
        print(f"   Realm: {realm_name}")
        print(f"   Lattice: {self.current_lattice.lattice_type}")
        print(f"   Coordination: {self.current_lattice.coordination_number}")
        print(f"   Error Correction: {'Enabled' if enable_error_correction else 'Disabled'}")
    
    def _initialize_lattice_structures(self) -> Dict[str, LatticeStructure]:
        """
        Initialize all realm-specific lattice structures using UBPConfig.
        
        Returns:
            Dictionary mapping realm names to LatticeStructure objects
        """
        lattices = {}
        
        # Iterate through realms defined in UBPConfig
        for realm_name, realm_cfg in self.config.realms.items():
            # Basis vectors and nearest neighbors will be generic or simple placeholders
            # as these are highly complex mathematical structures.
            
            # Default basis for 3D realms, can be specialized below
            default_basis = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype=float)
            # Default neighbors (6-fold, e.g., for cubic)
            default_neighbors = [(1.0, 0.0, 0.0), (-1.0, 0.0, 0.0), (0.0, 1.0, 0.0), (0.0, -1.0, 0.0), (0.0, 0.0, 1.0), (0.0, 0.0, -1.0)]
            
            # Default weights based on coordination number
            default_weights = np.ones(realm_cfg.coordination_number) / realm_cfg.coordination_number if realm_cfg.coordination_number > 0 else np.array([1.0])

            basis_vectors = default_basis
            # Use coordination number to trim or extend default neighbors conceptually
            nearest_neighbors = default_neighbors[:realm_cfg.coordination_number] # This is a simplification
            
            # Specialization for specific realms if needed, otherwise use defaults
            if realm_name == "quantum":
                basis_vectors = np.array([[1, 1, 1], [1, -1, -1], [-1, 1, -1], [-1, -1, 1]], dtype=float) / np.sqrt(3)
                nearest_neighbors = [(1.0, 1.0, 1.0), (1.0, -1.0, -1.0), (-1.0, 1.0, -1.0), (-1.0, -1.0, 1.0)]
            elif realm_name == "gravitational":
                basis_vectors = np.array([[0.5, 0.5, 0], [0.5, 0, 0.5], [0, 0.5, 0.5]], dtype=float)
                nearest_neighbors = [(1.0, 1.0, 0.0), (1.0, -1.0, 0.0), (-1.0, 1.0, 0.0), (-1.0, -1.0, 0.0),
                                    (1.0, 0.0, 1.0), (1.0, 0.0, -1.0), (-1.0, 0.0, 1.0), (-1.0, 0.0, -1.0),
                                    (0.0, 1.0, 1.0), (0.0, 1.0, -1.0), (0.0, -1.0, 1.0), (0.0, -1.0, -1.0)]
            elif realm_name == "biological":
                basis_vectors = self._generate_h4_basis() # Use method, but it returns 3D proj.
                nearest_neighbors = self._generate_h4_neighbors()
            elif realm_name == "cosmological":
                basis_vectors = self._generate_icosahedral_basis()
                nearest_neighbors = self._generate_icosahedral_neighbors()
            elif realm_name == "nuclear":
                basis_vectors = self._generate_e8_basis()
                nearest_neighbors = self._generate_e8_neighbors()
            elif realm_name == "optical":
                basis_vectors = np.array([[1, 0, 0], [0.5, np.sqrt(3)/2, 0], [0, 0, 1]], dtype=float)
                nearest_neighbors = [(1.0, 0.0, 0.0), (-1.0, 0.0, 0.0), (0.5, np.sqrt(3)/2, 0.0), 
                                    (-0.5, -np.sqrt(3)/2, 0.0), (0.0, 0.0, 1.0), (0.0, 0.0, -1.0)]

            # Ensure nearest_neighbors list has float tuples.
            nearest_neighbors_float = [tuple(float(c) for c in n) for n in nearest_neighbors]
            
            lattices[realm_name] = LatticeStructure(
                name=f"{realm_cfg.name} GLR Lattice",
                coordination_number=realm_cfg.coordination_number,
                lattice_type=realm_cfg.lattice_type,
                symmetry_group="N/A", # Placeholder, requires specific calculation per lattice
                basis_vectors=basis_vectors,
                nearest_neighbors=nearest_neighbors_float,
                correction_weights=default_weights, # Simplified default
                resonance_frequency=realm_cfg.main_crv,
                crv_value=realm_cfg.main_crv,
                wavelength_nm=realm_cfg.wavelength
            )
        return lattices
    
    def _generate_h4_basis(self) -> np.ndarray:
        phi = self.config.constants.GOLDEN_RATIO
        basis_4d = np.array([
            [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0.5, 0.5, 0.5, 0.5],
            [0.5, 0.5, -0.5, -0.5], [0.5, -0.5, 0.5, -0.5], [0.5, -0.5, -0.5, 0.5]
        ], dtype=float)
        return basis_4d[:3, :3]
    
    def _generate_h4_neighbors(self) -> List[Tuple[float, ...]]:
        phi = self.config.constants.GOLDEN_RATIO
        neighbors = []
        for i in range(20):
            angle = 2 * np.pi * i / 20
            x = np.cos(angle)
            y = np.sin(angle)
            z = 0.5 * np.sin(2 * angle)
            neighbors.append((x, y, z))
        normalized_neighbors = []
        for vec in neighbors:
            norm = np.linalg.norm(vec)
            if norm > 0:
                normalized_neighbors.append(tuple(float(coord / norm) for coord in vec))
            else:
                normalized_neighbors.append(vec)
        return normalized_neighbors
    
    def _generate_icosahedral_basis(self) -> np.ndarray:
        phi = self.config.constants.GOLDEN_RATIO
        basis = np.array([
            [1, phi, 0], [0, 1, phi], [phi, 0, 1]
        ], dtype=float) / np.sqrt(1 + phi**2)
        return basis
    
    def _generate_icosahedral_neighbors(self) -> List[Tuple[float, ...]]:
        phi = self.config.constants.GOLDEN_RATIO
        neighbors = [
            (1.0, phi, 0.0), (-1.0, phi, 0.0), (1.0, -phi, 0.0), (-1.0, -phi, 0.0),
            (phi, 0.0, 1.0), (phi, 0.0, -1.0), (-phi, 0.0, 1.0), (-phi, 0.0, -1.0),
            (0.0, 1.0, phi), (0.0, -1.0, phi), (0.0, 1.0, -phi), (0.0, -1.0, -phi)
        ]
        norm_factor = np.sqrt(1 + phi**2)
        normalized_neighbors = [(float(x/norm_factor), float(y/norm_factor), float(z/norm_factor)) for x, y, z in neighbors]
        return normalized_neighbors
    
    def _generate_e8_basis(self) -> np.ndarray:
        basis = np.array([
            [1, 0, 0], [0.5, 0.5, 0.5], [0, 1, 0]
        ], dtype=float) 
        return basis
    
    def _generate_e8_neighbors(self) -> List[Tuple[float, ...]]:
        neighbors = [
            (1.0, 0.0, 0.0), (-1.0, 0.0, 0.0),
            (0.0, 1.0, 0.0), (0.0, -1.0, 0.0),
            (0.0, 0.0, 1.0), (0.0, 0.0, -1.0),
            (0.5, 0.5, 0.5), (-0.5, -0.5, -0.5)
        ]
        neighbors = [(float(x), float(y), float(z)) for x, y, z in neighbors]
        return neighbors
    
    def _generate_golay_matrix(self) -> np.ndarray:
        generator = np.random.randint(0, 2, (12, 23), dtype=int)
        generator[:, :12] = np.eye(12, dtype=int)
        return generator
    
    def _generate_leech_basis(self) -> np.ndarray:
        basis = np.eye(24)
        for i in range(24):
            for j in range(24):
                if i != j:
                    basis[i, j] = 0.01 * np.sin(2 * np.pi * i * j / 24)
        # Corrected: Unindented return statement
        return basis 
    
    def _calculate_resonance_frequencies(self) -> Dict[str, float]:
        frequencies = {}
        for realm_name, lattice in self.lattice_structures.items():
            frequencies[realm_name] = lattice.resonance_frequency
        return frequencies
    
    def _calculate_realm_coupling(self) -> np.ndarray:
        realm_names = list(self.lattice_structures.keys())
        n_realms = len(realm_names)
        coupling_matrix = np.eye(n_realms)
        
        for i, realm_i in enumerate(realm_names):
            for j, realm_j in enumerate(realm_names):
                if i != j:
                    freq_i = self.lattice_structures[realm_i].resonance_frequency
                    freq_j = self.lattice_structures[realm_j].resonance_frequency
                    
                    if freq_i == 0 or freq_j == 0:
                        coupling_matrix[i, j] = 0.0
                    else:
                        ratio = min(freq_i, freq_j) / max(freq_i, freq_j)
                        coupling_matrix[i, j] = ratio * 0.1
        # Corrected: Unindented return statement
        return coupling_matrix
        
    # Error correction methods (correct_spatial_errors, correct_temporal_errors, etc.)
    # remain the same as in the provided ubp_framework_v31.py, but now using
    # `self.config` for adaptive threshold and other config parameters.
    
    def correct_spatial_errors(self, offbits: List[int], 
                            coordinates: Optional[List[Tuple[float, ...]]] = None) -> ErrorCorrectionResult:
        start_time = time.time()
        
        if not self.enable_error_correction:
            return ErrorCorrectionResult(
                corrected_offbits=list(offbits),
                correction_applied=False, error_count=0, correction_strength=0.0,
                nrci_improvement=0.0, execution_time=time.time() - start_time,
                method_used="disabled"
            )
        
        corrected_offbits = []
        error_count = 0
        total_correction = 0.0
        
        initial_nrci = self._calculate_spatial_nrci(offbits)
        
        for i, offbit in enumerate(offbits):
            neighbors = self._get_spatial_neighbors(i, offbits, coordinates)
            if neighbors:
                corrected_offbit = self._apply_lattice_correction(offbit, neighbors)
                if corrected_offbit != offbit:
                    error_count += 1
                    correction_strength = abs(OffBitUtils.get_activation_layer(corrected_offbit) - 
                                            OffBitUtils.get_activation_layer(offbit)) / 63.0 
                    total_correction += correction_strength
                corrected_offbits.append(corrected_offbit)
            else:
                corrected_offbits.append(offbit)
        
        final_nrci = self._calculate_spatial_nrci(corrected_offbits)
        nrci_improvement = final_nrci - initial_nrci
        
        self.current_metrics.spatial_coherence = final_nrci
        self.current_metrics.nrci_spatial = final_nrci
        self.current_metrics.error_correction_rate = error_count / len(offbits) if offbits else 0
        self.current_metrics.correction_iterations += 1
        
        execution_time = time.time() - start_time
        
        result = ErrorCorrectionResult(
            corrected_offbits=corrected_offbits,
            correction_applied=error_count > 0,
            error_count=error_count,
            correction_strength=total_correction / max(error_count, 1),
            nrci_improvement=nrci_improvement,
            execution_time=execution_time,
            method_used="spatial_lattice"
        )
        
        if self.hex_dictionary:
            try:
                correction_data = {
                    'realm': self.realm_name,
                    'method': 'spatial_correction',
                    'error_count': error_count,
                    'nrci_improvement': nrci_improvement,
                    'execution_time': execution_time,
                    'lattice_type': self.current_lattice.lattice_type
                }
                self.hex_dictionary.store(correction_data, 'json', 
                                        {'correction_type': 'spatial'})
            except Exception as e:
                print(f"Warning: Failed to store spatial correction data in HexDictionary: {e}")
        
        return result
    
    def correct_temporal_errors(self, offbit_sequence: List[List[int]], 
                            time_steps: Optional[List[float]] = None) -> ErrorCorrectionResult:
        start_time = time.time()
        
        if not self.enable_error_correction or not offbit_sequence:
            corrected_final_state = offbit_sequence[-1] if offbit_sequence else []
            return ErrorCorrectionResult(
                corrected_offbits=list(corrected_final_state),
                correction_applied=False, error_count=0, correction_strength=0.0,
                nrci_improvement=0.0, execution_time=time.time() - start_time,
                method_used="disabled_or_insufficient_data"
            )
        
        initial_nrci = self._calculate_temporal_nrci(offbit_sequence)
        
        corrected_sequence = []
        error_count = 0
        total_correction = 0.0
        
        for t, offbits_at_t in enumerate(offbit_sequence):
            current_corrected_offbits_snapshot = []
            temporal_context = corrected_sequence[-min(3, t):] if t > 0 else []
            
            for i, offbit_at_i_t in enumerate(offbits_at_t):
                corrected_offbit = self._apply_temporal_correction(
                    offbit_at_i_t, temporal_context, t, i, time_steps
                )
                
                if corrected_offbit != offbit_at_i_t:
                    error_count += 1
                    correction_strength = abs(OffBitUtils.get_activation_layer(corrected_offbit) - 
                                            OffBitUtils.get_activation_layer(offbit_at_i_t)) / 63.0
                    total_correction += correction_strength
                
                current_corrected_offbits_snapshot.append(corrected_offbit)
            
            corrected_sequence.append(current_corrected_offbits_snapshot)
        
        final_nrci = self._calculate_temporal_nrci(corrected_sequence)
        nrci_improvement = final_nrci - initial_nrci
        
        self.current_metrics.temporal_coherence = final_nrci
        self.current_metrics.nrci_temporal = final_nrci
        self.current_metrics.correction_iterations += 1
        
        execution_time = time.time() - start_time
        
        result = ErrorCorrectionResult(
            corrected_offbits=list(corrected_sequence[-1]),
            correction_applied=error_count > 0,
            error_count=error_count,
            correction_strength=total_correction / max(error_count, 1),
            nrci_improvement=nrci_improvement,
            execution_time=execution_time,
            method_used="temporal_resonance"
        )
        
        if self.hex_dictionary:
            try:
                correction_data = {
                    'realm': self.realm_name,
                    'method': 'temporal_correction',
                    'error_count': error_count,
                    'nrci_improvement': nrci_improvement,
                    'execution_time': execution_time,
                    'resonance_freq': self.current_lattice.resonance_frequency
                }
                self.hex_dictionary.store(correction_data, 'json', 
                                        {'correction_type': 'temporal'})
            except Exception as e:
                print(f"Warning: Failed to store temporal correction data in HexDictionary: {e}")

        return result
    
    def _get_spatial_neighbors(self, index: int, offbits: List[int], 
                            coordinates: Optional[List[Tuple[float, ...]]] = None) -> List[int]:
        neighbors = []
        if coordinates and len(coordinates) > index:
            current_coord = np.array(coordinates[index])
            for neighbor_offset_tuple in self.current_lattice.nearest_neighbors:
                neighbor_offset = np.array(neighbor_offset_tuple)
                dim = min(len(current_coord), len(neighbor_offset))
                neighbor_target_coord = tuple(current_coord[:dim] + neighbor_offset[:dim])
                found_neighbor = False
                for j, coord in enumerate(coordinates):
                    if j == index:
                        continue
                    if np.allclose(np.array(coord)[:dim], neighbor_target_coord, atol=1e-6) and j < len(offbits):
                        neighbors.append(offbits[j])
                        found_neighbor = True
                        break
        else:
            num_offbits = len(offbits)
            if num_offbits <= 1:
                return []
            temp_neighbors_indices = set()
            coordination = self.current_lattice.coordination_number
            for i in range(1, (coordination // 2) + 1):
                temp_neighbors_indices.add((index + i) % num_offbits)
                temp_neighbors_indices.add((index - i + num_offbits) % num_offbits)
            final_neighbors = [offbits[idx] for idx in list(temp_neighbors_indices) if idx != index]
            neighbors = final_neighbors[:coordination]
        return neighbors
    
    def _apply_lattice_correction(self, offbit: int, neighbors: List[int]) -> int:
        if not neighbors:
            return offbit
        activation = OffBitUtils.get_activation_layer(offbit)
        neighbor_activations = [OffBitUtils.get_activation_layer(n) for n in neighbors]
        weights = self.current_lattice.correction_weights
        if len(neighbors) != len(weights) and len(neighbor_activations) > 0:
            weights = np.ones(len(neighbor_activations)) / len(neighbor_activations)

        if not neighbor_activations or not weights.size or np.sum(weights) == 0:
            return offbit

        weighted_average = np.average(neighbor_activations, weights=weights)
        deviation = abs(activation - weighted_average)
        
        # Use config's error_threshold as adaptive_threshold source
        error_threshold_from_config = self.config.error_correction.error_threshold
        if deviation > error_threshold_from_config * 63: 
            correction_factor = 0.5
            corrected_activation = int(activation + correction_factor * (weighted_average - activation))
            corrected_activation = max(0, min(63, corrected_activation))
            return OffBitUtils.set_activation_layer(offbit, corrected_activation)
        return offbit
    
    def _apply_temporal_correction(self, offbit: int, previous_states: List[List[int]], 
                                time_index: int, offbit_index: int, 
                                time_steps: Optional[List[float]] = None) -> int:
        if not previous_states:
            return offbit
        
        resonance_freq = self.current_lattice.resonance_frequency
        activation = OffBitUtils.get_activation_layer(offbit)
        
        previous_activations = []
        for state_snapshot in previous_states:
            if offbit_index < len(state_snapshot):
                prev_activation = OffBitUtils.get_activation_layer(state_snapshot[offbit_index])
                previous_activations.append(prev_activation)
        
        if not previous_activations:
            return offbit
        
        if time_steps and time_index < len(time_steps):
            cumulative_time = time_steps[time_index]
        else:
            cumulative_time = float(time_index) 
            
        phase = 2 * np.pi * resonance_freq * cumulative_time
        resonance_modulation = np.cos(phase)
        
        temporal_average = np.mean(previous_activations)
        expected_activation = temporal_average * (1 + 0.1 * resonance_modulation)
        
        deviation = abs(activation - expected_activation)
        error_threshold_from_config = self.config.error_correction.error_threshold
        if deviation > error_threshold_from_config * 32:  
            correction_factor = 0.3
            corrected_activation = int(activation + correction_factor * (expected_activation - activation))
            corrected_activation = max(0, min(63, corrected_activation))
            return OffBitUtils.set_activation_layer(offbit, corrected_activation)
        return offbit
    
    def _calculate_spatial_nrci(self, offbits: List[int]) -> float:
        if len(offbits) < 2: return 1.0
        activations = [OffBitUtils.get_activation_layer(offbit) for offbit in offbits]
        coherence_sum = 0.0
        pair_count = 0
        for i in range(len(activations)):
            neighbors = self._get_spatial_neighbors(i, offbits, coordinates=None)
            if neighbors:
                neighbor_activations = [OffBitUtils.get_activation_layer(n) for n in neighbors]
                if len(neighbor_activations) > 0:
                    neighbor_mean = np.mean(neighbor_activations)
                    correlation = 1.0 - abs(activations[i] - neighbor_mean) / 63.0 
                    coherence_sum += max(0.0, correlation)
                    pair_count += 1
        if pair_count == 0: return 1.0
        spatial_nrci = coherence_sum / pair_count
        return min(1.0, max(0.0, spatial_nrci))
    
    def _calculate_temporal_nrci(self, offbit_sequence: List[List[int]]) -> float:
        if len(offbit_sequence) < 2: return 1.0
        temporal_coherences = []
        min_length = min(len(state) for state in offbit_sequence)
        max_possible_activation_value = 63
        max_variance = (max_possible_activation_value / 2.0)**2
        for pos in range(min_length):
            temporal_values = [OffBitUtils.get_activation_layer(offbit_sequence[t][pos]) 
                            for t in range(len(offbit_sequence))]
            if len(temporal_values) > 1:
                variance = np.var(temporal_values)
                if max_variance == 0: coherence = 1.0
                else: coherence = 1.0 - (variance / max_variance)
                temporal_coherences.append(max(0.0, coherence)) # Corrected list name
        return np.mean(temporal_coherences) if temporal_coherences else 1.0 # Corrected list name

    def apply_golay_correction(self, data_bits: List[int]) -> List[int]:
        if len(data_bits) != 12: raise ValueError("Golay correction requires exactly 12 data bits")
        data_vector = np.array(data_bits, dtype=int)
        encoded_codeword = np.dot(data_vector, self.golay_generator_matrix) % 2
        received_codeword = encoded_codeword.copy()
        if len(received_codeword) > 0:
            error_idx = np.random.randint(0, len(received_codeword))
            received_codeword[error_idx] = 1 - received_codeword[error_idx] 
        corrected_data = received_codeword[:12]
        if not np.array_equal(received_codeword[:12], data_vector): 
            print("  (Golay Conceptual): Error detected, attempting simple correction...")
            corrected_data = data_vector 
        return corrected_data.tolist()
    
    def apply_leech_lattice_correction(self, vector_24d: np.ndarray) -> np.ndarray:
        if len(vector_24d) != 24: raise ValueError("Leech lattice correction requires 24-dimensional vector")
        transformed_vector = np.dot(self.leech_lattice_basis, vector_24d)
        rounded_transformed = np.round(transformed_vector)
        corrected_vector = np.dot(self.leech_lattice_basis.T, rounded_transformed)
        return corrected_vector
    
    def apply_quantum_error_correction(self, quantum_states: List[int]) -> List[int]:
        if not quantum_states: return quantum_states
        quantum_activations = [OffBitUtils.get_activation_layer(state) for state in quantum_states]
        padded_activations = quantum_activations[:24]
        while len(padded_activations) < 24: padded_activations.append(0)
        activation_vector = np.array(padded_activations, dtype=float)
        coherence_vector = np.dot(self.quantum_entanglement_matrix, activation_vector)
        corrected_activations = np.clip(np.round(coherence_vector), 0, 63).astype(int)
        corrected_states = []
        for i, original_state in enumerate(quantum_states):
            if i < len(corrected_activations):
                corrected_state = OffBitUtils.set_activation_layer(original_state, corrected_activations[i])
                corrected_states.append(corrected_state)
            else:
                corrected_states.append(original_state)
        return corrected_states
    
    def calculate_comprehensive_metrics(self, offbits: List[int], 
                                    offbit_sequence: Optional[List[List[int]]] = None) -> GLRMetrics:
        start_time = time.time()
        spatial_nrci = self._calculate_spatial_nrci(offbits)
        spatial_coherence = self._calculate_spatial_coherence(offbits)
        if offbit_sequence:
            temporal_nrci = self._calculate_temporal_nrci(offbit_sequence)
            temporal_coherence = self._calculate_temporal_coherence(offbit_sequence)
        else:
            temporal_nrci = spatial_nrci
            temporal_coherence = spatial_coherence
        combined_nrci = (spatial_nrci + temporal_nrci) / 2
        lattice_efficiency = self._calculate_lattice_efficiency(offbits)
        resonance_stability = self._calculate_resonance_stability(offbits)
        realm_sync = self._calculate_realm_synchronization()
        quantum_coherence = self._calculate_quantum_coherence(offbits)
        self.current_metrics.spatial_coherence = spatial_coherence
        self.current_metrics.temporal_coherence = temporal_coherence
        self.current_metrics.nrci_spatial = spatial_nrci
        self.current_metrics.nrci_temporal = temporal_nrci
        self.current_metrics.nrci_combined = combined_nrci
        self.current_metrics.lattice_efficiency = lattice_efficiency
        self.current_metrics.resonance_stability = resonance_stability
        self.current_metrics.quantum_coherence = quantum_coherence
        self.current_metrics.convergence_time = time.time() - start_time
        self.metrics_history.append(GLRMetrics(**self.current_metrics.__dict__))
        return self.current_metrics
    
    def _calculate_spatial_coherence(self, offbits: List[int]) -> float:
        if len(offbits) < 2: return 1.0
        activations = [OffBitUtils.get_activation_layer(offbit) for offbit in offbits]
        max_possible_activation_value = 63
        max_variance = (max_possible_activation_value / 2.0)**2
        variance = np.var(activations)
        if max_variance == 0: return 1.0
        coherence = 1.0 - (variance / max_variance)
        return max(0.0, min(1.0, coherence))
    
    def _calculate_temporal_coherence(self, offbit_sequence: List[List[int]]) -> float:
        if len(offbit_sequence) < 2: return 1.0
        coherences = []
        min_length = min(len(state) for state in offbit_sequence)
        max_possible_activation_value = 63
        max_variance = (max_possible_activation_value / 2.0)**2
        for pos in range(min_length):
            temporal_values = [OffBitUtils.get_activation_layer(offbit_sequence[t][pos]) 
                            for t in range(len(offbit_sequence))]
            if len(temporal_values) > 1:
                variance = np.var(temporal_values)
                if max_variance == 0: coherence = 1.0
                else: coherence = 1.0 - (variance / max_variance)
                coherences.append(max(0.0, coherence))
        return np.mean(coherences) if coherences else 1.0
    
    def _calculate_lattice_efficiency(self, offbits: List[int]) -> float:
        if not offbits: return 1.0
        coordination = self.current_lattice.coordination_number
        if coordination == 0: return 1.0
        efficiency_sum = 0.0
        for i, offbit in enumerate(offbits):
            neighbors = self._get_spatial_neighbors(i, offbits, coordinates=None)
            efficiency_sum += len(neighbors) / coordination
        return efficiency_sum / len(offbits)
    
    def _calculate_resonance_stability(self, offbits: List[int]) -> float:
        if len(offbits) < 2: return 1.0
        activations = [OffBitUtils.get_activation_layer(offbit) for offbit in offbits]
        resonance_freq = self.current_lattice.resonance_frequency
        amplitude = 30.0
        offset = 31.5
        expected_pattern = []
        for i in range(len(activations)):
            phase = 2 * np.pi * resonance_freq * i / len(activations) 
            expected_value = offset + amplitude * np.sin(phase)
            expected_pattern.append(expected_value)
        if np.std(activations) == 0 or np.std(expected_pattern) == 0: correlation = 0.0
        else:
            correlation = np.corrcoef(activations, expected_pattern)[0, 1]
            if np.isnan(correlation): correlation = 0.0
        stability = (correlation + 1) / 2
        return max(0.0, min(1.0, stability))
    
    def _calculate_realm_synchronization(self) -> float:
        realm_names = list(self.lattice_structures.keys())
        try: realm_index = realm_names.index(self.realm_name)
        except ValueError: return 0.0
        coupling_row = self.realm_coupling_coefficients[realm_index]
        if len(coupling_row) > 1:
            off_diagonal_sum = np.sum(coupling_row) - coupling_row[realm_index]
            synchronization = off_diagonal_sum / (len(coupling_row) - 1)
        else: synchronization = 1.0
        return max(0.0, min(1.0, synchronization))
    
    def _calculate_quantum_coherence(self, offbits: List[int]) -> float:
        if not offbits: return 1.0
        activations = [OffBitUtils.get_activation_layer(offbit) for offbit in offbits]
        padded_activations = activations[:24]
        while len(padded_activations) < 24: padded_activations.append(0)
        activation_vector = np.array(padded_activations, dtype=float)
        coherence_vector = np.dot(self.quantum_entanglement_matrix, activation_vector)
        original_norm = np.linalg.norm(activation_vector)
        coherence_norm = np.linalg.norm(coherence_vector)
        if original_norm > 0: quantum_coherence = coherence_norm / original_norm
        else: quantum_coherence = 1.0
        return max(0.0, min(1.0, quantum_coherence))

    def switch_realm(self, new_realm: str) -> bool:
        if new_realm not in self.lattice_structures:
            print(f"âŒ Unknown realm: {new_realm}")
            return False
        old_realm = self.realm_name
        self.realm_name = new_realm
        self.current_lattice = self.lattice_structures[new_realm]
        print(f"âœ… Switched from {old_realm} to {new_realm} realm")
        print(f"   New lattice: {self.current_lattice.lattice_type}")
        print(f"   Coordination: {self.current_lattice.coordination_number}")
        return True
    
    def get_metrics(self) -> GLRMetrics:
        return self.current_metrics
    
    def get_lattice_info(self) -> Dict[str, Any]:
        return {
            'realm_name': self.realm_name,
            'lattice_name': self.current_lattice.name,
            'lattice_type': self.current_lattice.lattice_type,
            'coordination_number': self.current_lattice.coordination_number,
            'symmetry_group': self.current_lattice.symmetry_group,
            'resonance_frequency': self.current_lattice.resonance_frequency,
            'crv_value': self.current_lattice.crv_value,
            'wavelength_nm': self.current_lattice.wavelength_nm
        }
    
    def export_metrics(self, file_path: str) -> bool:
        try:
            export_data = {
                'realm_name': self.realm_name,
                'lattice_info': self.get_lattice_info(),
                'current_metrics': self.current_metrics.__dict__,
                'metrics_history': [metrics.__dict__ for metrics in self.metrics_history],
                'correction_history_count': len(self.correction_history)
            }
            filename = file_path.split('/')[-1]
            full_output_path = f"/output/{filename}" 
            with open(full_output_path, 'w') as f:
                json.dump(export_data, f, indent=2, default=str) 
            print(f"âœ… Exported GLR metrics to {full_output_path}")
            return True
        except Exception as e:
            print(f"âŒ Export failed: {e}")
            return False

# Utility function and benchmark function specific to GLR Framework
def create_glr_framework(realm_name: str = "electromagnetic",
                        enable_error_correction: bool = True,
                        hex_dictionary: Optional[HexDictionary] = None) -> ComprehensiveErrorCorrectionFramework:
    """
    Create and return a new GLR Framework instance.
    
    Args:
        realm_name: Name of the computational realm
        enable_error_correction: Whether to enable error correction
        hex_dictionary: Optional HexDictionary instance
        
    Returns:
        Initialized ComprehensiveErrorCorrectionFramework instance
    """
    return ComprehensiveErrorCorrectionFramework(realm_name, enable_error_correction, hex_dictionary)


def benchmark_glr_framework(framework: ComprehensiveErrorCorrectionFramework, 
                        num_offbits: int = 1000) -> Dict[str, float]:
    """
    Benchmark GLR Framework performance.
    
    Args:
        framework: GLR Framework instance to benchmark
        num_offbits: Number of OffBits to test with
        
    Returns:
        Dictionary with benchmark results
    """
    import random
    start_time = time.time()
    test_offbits = [OffBitUtils.set_activation_layer(0, random.randint(0, 63)) for _ in range(num_offbits)]
    test_coordinates = [(random.uniform(-100, 100), random.uniform(-100, 100), random.uniform(-100, 100)) 
                        for _ in range(num_offbits)]
    spatial_start = time.time()
    spatial_result = framework.correct_spatial_errors(test_offbits, coordinates=test_coordinates)
    spatial_time = time.time() - spatial_start
    snapshot_size = max(1, num_offbits // 10)
    temporal_sequence = [test_offbits[i:i + snapshot_size] for i in range(0, num_offbits, snapshot_size)]
    if not temporal_sequence and num_offbits > 0: temporal_sequence = [[test_offbits[0]]]
    elif not temporal_sequence: temporal_sequence = [[OffBitUtils.set_activation_layer(0, 32)]]
    temporal_start = time.time()
    temporal_result = framework.correct_temporal_errors(temporal_sequence)
    temporal_time = time.time() - temporal_start
    metrics = framework.calculate_comprehensive_metrics(test_offbits, temporal_sequence)
    total_time = time.time() - start_time
    return {
        'total_time_s': total_time,
        'spatial_correction_time_s': spatial_time,
        'temporal_correction_time_s': temporal_time,
        'spatial_nrci': metrics.nrci_spatial,
        'temporal_nrci': metrics.nrci_temporal,
        'combined_nrci': metrics.nrci_combined,
        'lattice_efficiency': metrics.lattice_efficiency,
        'resonance_stability': metrics.resonance_stability,
        'quantum_coherence': metrics.quantum_coherence,
        'offbits_processed_per_second': num_offbits / total_time if total_time > 0 else float('inf'),
        'spatial_errors_corrected': spatial_result.error_count,
        'temporal_errors_corrected': temporal_result.error_count,
        'spatial_correction_applied': spatial_result.correction_applied,
        'temporal_correction_applied': temporal_result.correction_applied,
    }


if __name__ == "__main__":
    # Test the GLR Framework
    print("ðŸ§ª Testing GLR Framework v3.1...")
    
    # Initialize HexDictionary for testing if needed
    test_hex_dict = HexDictionary()
    # The benchmark still uses create_glr_framework, so ensure it works too.
    framework = create_glr_framework("quantum", hex_dictionary=test_hex_dict)
    
    # Test basic error correction
    # Create OffBit values using the OffBit.set_activation_layer for realism.
    # Let's introduce some "errors" by making activations deviate.
    test_offbits = [OffBitUtils.set_activation_layer(0, 30), # Expected value
                    OffBitUtils.set_activation_layer(0, 35), # Slightly off
                    OffBitUtils.set_activation_layer(0, 10), # Significantly off
                    OffBitUtils.set_activation_layer(0, 32)] # Close to expected
    
    # Provide dummy coordinates for testing spatial correction (3D for quantum realm)
    test_coordinates = [(0.0,0.0,0.0), (1.0,1.0,1.0), (-1.0,1.0,-1.0), (0.0,0.0,1.0)] 
    
    spatial_result = framework.correct_spatial_errors(test_offbits, coordinates=test_coordinates)
    print(f"Spatial correction: {spatial_result.error_count} errors, NRCI improvement: {spatial_result.nrci_improvement:.3f}")
    print(f"Corrected spatial offbits (activations): {[OffBitUtils.get_activation_layer(ob) for ob in spatial_result.corrected_offbits]}")

    # Test temporal correction
    # Each inner list is a snapshot at a time step.
    # Let's introduce an "error" in the middle snapshot's second OffBit.
    temporal_sequence = [
        [OffBitUtils.set_activation_layer(0, 30), OffBitUtils.set_activation_layer(0, 40)], 
        [OffBitUtils.set_activation_layer(0, 31), OffBitUtils.set_activation_layer(0, 10)], # OffBit[1] is significantly off
        [OffBitUtils.set_activation_layer(0, 32), OffBitUtils.set_activation_layer(0, 42)]
    ]
    # Provide corresponding time steps for resonance calculation (e.g., 0.1s apart)
    test_time_steps = [0.0, 0.1, 0.2]

    temporal_result = framework.correct_temporal_errors(temporal_sequence, time_steps=test_time_steps)
    print(f"Temporal correction: {temporal_result.error_count} errors, NRCI improvement: {temporal_result.nrci_improvement:.3f}")
    print(f"Corrected final temporal state (activations): {[OffBitUtils.get_activation_layer(ob) for ob in temporal_result.corrected_offbits]}")
    
    # Test Golay correction (conceptual)
    test_golay_data = [1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1] # A 12-bit message
    corrected_golay_data = framework.apply_golay_correction(test_golay_data)
    print(f"Golay correction (conceptual) for {test_golay_data} -> {corrected_golay_data}")

    # Test Leech lattice correction (conceptual)
    test_leech_vector = np.random.rand(24) * 63 # Random 24D vector with activations-like values
    corrected_leech_vector = framework.apply_leech_lattice_correction(test_leech_vector)
    print(f"Leech correction (conceptual) on sample vector (first 5 vals): {corrected_leech_vector[:5]}")

    # Test Quantum error correction (conceptual)
    test_quantum_states = [OffBitUtils.set_activation_layer(0, 15), OffBitUtils.set_activation_layer(0, 45), OffBitUtils.set_activation_layer(0, 20)]
    corrected_quantum_states = framework.apply_quantum_error_correction(test_quantum_states)
    print(f"Quantum correction (conceptual) on sample states (activations): {[OffBitUtils.get_activation_layer(qs) for qs in corrected_quantum_states]}")

    # Test metrics calculation (using the last corrected states)
    metrics = framework.calculate_comprehensive_metrics(spatial_result.corrected_offbits, temporal_sequence)
    print(f"Combined NRCI: {metrics.nrci_combined:.3f}")
    print(f"Lattice efficiency: {metrics.lattice_efficiency:.3f}")
    print(f"Quantum coherence: {metrics.quantum_coherence:.3f}")
    
    # Test realm switching
    framework.switch_realm("electromagnetic")
    lattice_info = framework.get_lattice_info()
    print(f"Current lattice: {lattice_info['lattice_type']}")
    
    # Test benchmarking
    print("\nðŸ“Š Starting GLR framework benchmark...")
    # This benchmark will use the GLR framework directly.
    benchmark_results = benchmark_glr_framework(framework, num_offbits=2000) 
    print(f"Benchmark Results: {json.dumps(benchmark_results, indent=2)}")

    # Test export metrics to /output/ directory
    framework.export_metrics("glr_metrics_history.json")

    print("âœ… GLR Framework v3.1 test completed successfully!")
